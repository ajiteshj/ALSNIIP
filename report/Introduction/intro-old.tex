%%% Thesis Introduction --------------------------------------------------
\chapter{Introduction}
\ifpdf
    \graphicspath{{Introduction/IntroductionFigs/PNG/}{Introduction/IntroductionFigs/PDF/}{Introduction/IntroductionFigs/}}
\else
    \graphicspath{{Introduction/IntroductionFigs/EPS/}{Introduction/IntroductionFigs/}}
\fi

%\section{Motivation}
%\section{Scope}
%\section{Objectives}

\section{Motivation}
The rapid computerization and availability of high computing power have led to the emergence of social-networks. A brief insight about the topological and behavioural aspects of complex networks can be achieved by a thorough understanding of social networks. It is considered a very important topic for research due to the widespread success of social networking websites such as Facebook, Twitter and Linked-in.

Social networks are structures where nodes represent people or entities and edges represent interaction, influence or collaboration between entities. They grow and change quickly over time through the addition of new edges, signifying the appearance of new interactions in the underlying social structure. Social network analysis involves identifying mechanisms by which they grow and evolve. The major application of social networks are point to point overlay networks, security systems in ad-hoc networks, hybrid sensor networks, prediction and control of an epidemic, cellular telephone systems and it also helps us to predict links in the world wide web or any other given computer network.

\section{Objectives}
Social network analysis is our primary focus wherein we follow practices such as design, analysis, coding, testing and maintenance so that the evolution of the network can be observed over time. Huge data-sets are collected and assimilated which signify interaction between two or more social entities thus providing insights regarding how closely related they are, at what instance of time they interact and the duration of the interaction. The underlying concept or the phenomenon has to be proved by various methodologies such as algorithmic analysis either in a iterative or in a regressive fashion followed by modelling, visual representation, animation and detailed presentation.

Obtaining of preliminary results sheds some light on the very fact whether this approach gives us comprehensive and satisfying results in the near future. The underlying concept is proof-tested by applying on various data-sets obtained from heterogeneous sources. The results and findings from this experimental set-up help to identify relationships among social entities, derive patterns and accurately predict the future outcomes. Detailed results are obtained, thus enabling us to conclude their significance in a real world environment.

The interest of this project lies in social networking concepts such as social influence analysis, time series analysis, link prediction, cluster analysis, small world phenomenon and power law analysis. In the section below a brief description of these concepts is given.

\section{Elements of Network Analysis}

\subsection{Social Network Analysis (SNA)}

Increase in the use of personal computers in late 1980s has encouraged much wider use of SNA  methods because it has meant increased ability to manage large data sets and to visualize social network data in a wide variety of ways. Social network analysis (SNA) is the analysis of social networks. A social network is a social structure made up of a set of social actors (such as individuals or organizations) and a set of the dyadic ties between these actors.

The social network perspective provides a set of methods for analysing the structure of whole social entities as well as a variety of theories explaining the patterns observed in these structures. The study of these structures uses social network analysis to identify local and global patterns, locate influential entities, and examine network dynamics.

Social Network Analysis is the study of social relations among a set of actors. It concerns the network structure formulation and solution. Such structures are usually captured in graphs. Limelight on analysis was thrown very recently; until then it was invisible even to the organizations which depend on them. Every organisation has a network within itself since network is nothing but relationships among interacting units.

Social network analysis has now emerged from being a suggestive metaphor to an analytic approach to a paradigm, with its own theoretical statements. It has gained a significant following in anthropology, biology, communication studies, economics, geography, information science, organizational studies, social psychology and many other fields. In organisations collaboration in networks is critical to innovation. Paradoxically these networks are taken for granted, frequently invisible and rarely managed.

Social network analysis is focused on uncovering the patterns of people’s interactions. A rapid growth in work across organisation as well as geographic boundaries with outsourcing, off-shoring, virtual organisations and business process networks, combined with trends such as the rise of blogs, online communities and social networking sites such as Friendster and LinkedIn as well as the rapid growth of collaborative software have all contributed to the emergence of Social Network Analysis (SNA) from the academic closet.

Social relationships are viewed in terms of network theory (consisting of nodes and connections) by social network analysis. These networks are often depicted in a social network diagram, where nodes are the points and ties are the lines. Social network analysis is based on an assumption of the importance of relationships among interacting units.

The network’s perspective encompasses theories, models, and applications that are expressed in terms of relational concepts or processes. Along with growing interest and increased use of network analysis has come a consensus about the central principles underlying the network perspective.

Social Network Analysis (SNA) can be defined as a set of techniques underpinned by statistical analysis that make visible the hidden connections that are important for sharing information, decision-making and innovation in an organization.

\subsection{Concepts used by SNA}

Social network is the mapping and measuring of relationships and flows between people, groups, organizations, animals, computers or any other Information/Knowledge processing entities. Graphs, Matrices, Statistical Models and a few Formal methods like Graphical and Mathematical Models are used to visualize Social Networks. Maximum flow, Hubbell and Katz cohesion, Centrality and Power are the most influencing properties of a Social Network. Cliques, N-Clans and L-Plexes are the different Ideas used to study the Sub-Structures and Groups of a Social Network. The Web can be treated as a Social Network, weblogs as special subsets of web can also be considered as Social Networks. Page Rank in Google and HITS are a few Social Network Analyses applied on web contents for efficient search results for the user queries. The semantic web is an emerging concept that launches the idea of having data on the web defined and linked in a way that it can be used by people and processed by machines. The semantic web and social network models support each other.

{\bf Graph Mining}

Graphs have become extremely important in modelling complicated structures. Many domains produce data that can be intuitively represented by graphs. The process of discovering interesting facts and information about these graphs is difficult and challenging to work with because real world data is very huge for any sort of raw interpretation, so that graph mining which is a data mining approach has to be incorporated with SNA to obtain the results of the data sets so as to provide us with an insight of the frequent sub graphs of interest.

{\bf Link Analysis}

Link mining works with graph structures that have nodes with defined set of properties. With more and more information becoming available today in databases, structured documents, plain texts, transcribed conversations, and sometimes even in non-verbal form, such as images and videos, the possibilities for link analysis, as well as the associated challenges, are growing by leaps and bounds. Link Prediction is a kind of Link Analysis technique used in SNA to find out the future links that are most likely to occur based on the analysis of the data.

{\bf Centrality and Betweeness}

Importance of each node in a Social Network is varied based on its influence in the whole network. Measuring the rank of a node in any large network is thus a very crucial task. Social Network Analysis helps to determine rank or the centrality of the actors according to their position in the social structure using the knowledge of connectivity. Betweeness Centrality (BC) helps to get a more precise rank of the actors in the network by involving more global information such as its role played in the existence of paths between any two given nodes in the network. Three heuristic algorithms are proposed for influential nodes selection after detecting communities in Social Networks. These algorithms outperform the greedy algorithm and traditional heuristics in terms of speed .

{\bf Density}

The density of a graph is the number of existing edges over the number of possible edges. It represents the connectedness of nodes in a graph. Higher density in graphs shows the most active regions and implies that more activities are occurring at exponential rates like new actors joining and new relations being formed. This leads to repeated analysis for new insights that can be obtained.


{\bf Clustering}

Clustering is the most important topic that deals with unsupervised data. It deals with finding a structure in a collection of unlabelled data. A cluster is therefore a collection of objects which are similar between them and are dissimilar to the objects belonging to other clusters. Hence, the goal of clustering is to determine the intrinsic grouping in a set of unlabelled data.

{\bf Classification}

Classification is the supervised way of using known properties to categorize the data with unknown properties. In inter graph classification the graphs are classified under different labels based on the properties of the data inside graphs. Classification model is built using machine learning techniques based on the known properties of graphs, and the graphs with unknown properties are classified based on the model.

{\bf Average Path Length} 

In a network, the distance between two nodes is the number of edges in the shortest path connecting them. The diameter D is the maximal distance between any pairs of nodes. The average path length L is defined as the mean distance between any two nodes. It was an interesting discovery that the average path length of most real complex network is relatively small, even in those kinds of networks which have fewer edges than a globally coupled network with an equal number of nodes. This kind of smallness is inferred as small world effect. 

{\bf Clustering Coefficient} 

The common phenomenon of existence of the mutual friend concept is simply that two friends usually have a common acquaintance, or it so happens that a person gets to know another person through a friend. This property naturally leads to clustering inside a given network where we come across the concept of clustering coefficient C. This can be defined as the average fraction of pairs of neighbours of a node that are also neighbours of each other. 

{\bf Degree Distribution} 

The most important feature of any given node is its degree. The degree is characterized by the total number of connections. Hence greater the degree of the network higher is the importance of that node in the network. The degree sequences obeys the Poisson distribution. The power law distribution falls off more gradually than an exponential one, allowing for a few nodes of very large degree to exist. As power laws are free of any characteristics scale, such a network with a power law degree distribution is called a scale free network. In order to analyse the small world phenomenon we make use of mathematical models and graphs. In one of the graphs we concluded that the logarithmic increase in average path length with the size of the network is typically a small world effect. This logarithmic graph gives us a better essence and understanding of complex networks. A very important concept, `richer become richer' is exhibited in complex network systems where all nodes concentrate at a given point.

{\bf Applications of SNA}

• Civil society organizations use SNA to uncover conflicts of interest in hidden connections between government bodies, lobbies and businesses, Network operators (telephone, cable, mobile) use SNA-like methods to optimize the structure and capacity of their networks
• Businesses use SNA to analyse and improve communication flow in their organization, or with their networks of partners and customers
• Law enforcement agencies (and the army) use SNA to identify criminal and terrorist networks from traces of communication that they collect; and then identify key players in these networks
• Computer scientists have used network analysis methods to study webpages, Internet traffic, information dissemination, etc.
• Social Network Sites like Facebook use basic elements of SNA to identify and recommend potential friends based on friends-of-friends
• Social Network Analysis is used to determine influential journalists and analysts in the IT industry.
• Mapping executive’s personal network based on email flows can be done using Social Network Analysis.



\subsection{Small World Phenomenon}

An experiment conducted by a social psychologist Stanley Milgram during 1960 in the United States of America in order to find the average path lengths of social networks made use of small world type of networks. The aim of the experiment was to study the complexity of communication when a given message was exchanged between any two random people living in different parts of the country, that is
when a source person had to deliver a message to a target person. Milgram himself with a set of other mathematicians, handed out letters to people in Boston, and these people were asked to deliver the given letter to a target person in Massachusetts whose personal information such as name occupation and address was given but the letters had to be passed on as fast as possible to another person whom they knew but on only a first-name basis. 

After the experiment concluded it was found that atmost five or six people were involved in the exchanging of most of the messages (short chains of acquaintances), hence the phrase six degrees of separation, here at least two of them being intermediaries. It was concluded that the given letter would reach faster if the given person was socially accessible and affluent. It was also inferred that there existed very short paths between arbitrary nodes. Individuals having local information are very suited for finding these paths. Milgram’s work was considered to be the first empirical evidence of social networks. The most critical fact of this experiment is that such short paths can be also seen in social networks which helps us to successfully analyse a huge set of given data.

It is still considered a very important topic for research due to the widespread of social networking websites such as Facebook, MSN messenger or due to the importance of social networks in general. Advent of many natural and complex networks has stimulated a great deal of interest in the concept of small world and the principles underlying them. Networks are structures of nodes or vertices connected by links or edges, for example, the World Wide Web. Rapid computerization of data and availability of high computer power have led to the emergence of complex networks and social networks in general.

In small-world we come across exponential networks or homogeneous networks in which the network size peaks at an average value and then goes on to decay exponentially, it is so because of the same number of link connections. An observation was made in the field of complex networks in which large scale complex networks are scale free which means their connectivity distributions are in a power law form, which means they are independent of the network scale. The main difference between a scale free network and exponential network is that most nodes have very few link connections and yet a few nodes have many connections. With the help of scale free networks and small world it gives us a brief insight about the topological and behavioural aspects of complex network.  

The major application of the small world phenomenon are point to point overlay networks, security systems in adhoc networks, hybrid sensor networks, prediction and control of an epidemic, cellular telephone systems and it helps us to predict links in the world wide web or any given computer network.

\subsection{Power Law}

A Power Law is a mathematical relationship between two quantities, where one quantity varies as a fixed power of another. A network whose degree distribution follows a power law is called a scale-free network. A graph for power law follows a long/heavy tailed distribution. The power law graph can be used to demonstrate the ranking of popularity of nodes and predict the region of interest of a particular node in a network. The procedure for verifying power law for a network is a dynamic approach, where data are analysed over a period of time.

\subsection{Link Prediction}

Given a snapshot of a social network, can we infer which new interactions among its members are likely to occur in the near future? This question is formalized as the link prediction problem, and we develop approaches to link prediction based on measures for analysing the proximity of nodes in a network. Experiments on large co-authorship networks suggest that information about future interactions can be extracted from network topology alone, and that fairly subtle measures for detecting node proximity can outperform more direct measures.

The task of predicting links that are either missing or may appear in the future is addressed by link prediction. The methods proposed to cope with the link prediction problem are divided into two categories: unsupervised and supervised methods. Unsupervised methods assign a score for each pair of nodes using either local or global neighbourhood information. Experimental results on different social networks show that these methods are time consuming and are not feasible for large social networks. Supervised methods on the other hand consider link prediction as a classification problem. It uses different network information such as structural properties of the network, node attributes to determine the link existence between a pair of nodes. However, it does not use other information such as behaviour of nodes. It concentrates only on the existence of the links and not the properties of individuals that the nodes represent. In order to overcome such drawbacks, hybrid methods are developed which consider local information as well as community information.

Given a network, the probabilities of link existence and nonexistence of all the links in the network are computed. To determine the probability of a non-existent link, a hybrid method is established which uses Bayesian theory. For the weighted relationships among the nodes in a large network, the probabilities of existence of any link in the network are computed. Next, clustering is performed to obtain the different communities present in the network. For pairs of nodes which are not linked, the number of common neighbours between the nodes within and outside of their communities are determined.

From the parameters calculated so far, the posterior probabilities of link existence and nonexistence for the pairs of nodes are computed. A similarity score for the pairs of nodes is calculated as the ratio of posterior probability of link existence to the posterior probability of nonexistence. The computed scores are sorted in decreasing order to show that links with higher probability will come into existence earlier than those with lower probabilities.

\subsection{Clustering}

One of the most important applications of graphs is to represent real systems as a graphical network so as to detect community structure, or clustering, i.e. the organization of vertices in clusters, with many edges joining vertices of the same cluster and comparatively few edges joining vertices of different clusters. Such clusters, or communities, can be considered as fairly independent compartments of a graph. Being able to identify these sub-structures within a network can provide insights into how network function and topology affect each other. Such insights can be useful in improving some algorithms on graphs such as spectral clustering. Various clustering methods exist based on statistical
and machine learning techniques. Some of the most useful methods are discussed and applied in later
sections.

Detecting communities is of great importance in sociology, biology and computer science, disciplines where systems are often represented as graphs.


\subsection{Weight Assignment}

It is necessary to obtain a clear perspective of the networks to carry out effective analysis. In general, networks can be weighted or un-weighted. The drawback of using un-weighted networks is the lack of real world representation. Therefore the analysis of these networks is difficult. Hence it is necessary to assign weights to the ties among the nodes in a network. Weights are assigned to the edges by considering the features of the network and properties of graph theory. The network features include timestamps, influence, interactions, relationships and emotions. The properties are centrality, betweeness, clustering coefficient and power-law behaviour. In some cases it is useful to come up with alternative definitions of centrality, cohesiveness and affinity. 

Weight assignment involves the following steps:
Initially a feature-rich dataset is obtained and converted to useful form. Score of the network is computed which is based on similarity feature and the score is associated with each edge to obtain the final weight. Advantages of using weighted networks are they emulate the structure of real social networks thus enable to display community structures with weak and strong internal links connecting the communities: facilitation of better understanding of complex networks by providing a complete view of the network and effective results are obtained from rigorous analysis. 

Feature or attribute weighting finds applications in content-based recommender systems and profile matching in social networks. Here weighted network data is used to perform influence analysis and link prediction. 

\subsection{Influence Analysis}

An attempt is made using social network analysis to answer the question, ”Who are the most influential individuals in a network?” Influential individuals are said to be those who are capable of convincing other individuals to adapt their attitude, behaviour, or belief to that of the former. Identifying the key influential individuals in a network can play a key role in the introduction, longevity, and fidelity of program implementation.

Given a set of weighted, directed relations among the individuals in a large network, clustering based on the fast greedy algorithm  is initially performed on this network to identify closely related sub-networks of individuals. Next, these clusters are analysed one by one as independent organizations. The PageRank  of all the individuals in the cluster are computed in order to determine their local standing (relative to the cluster). For each individual A, the weights that A has assigned to every other individual in the cluster is multiplied by the PageRank of A in order to incorporate the influence of A. With these updated weights, the in-degree centrality (also known as in-ties) is computed and then used as a measure of the total communication directed at each individual. For each individual, the in-tie measure indicates how well other individuals in the cluster weigh this individual. Individuals who receive higher scores are considered more influential in the network.

In order to visualize the distribution of the in-degree measure within an organization, the in-degree scores for all individuals can be sorted in descending order and then graphed, resulting in a ”scree” plot. This technique allows a researcher to get a sense of the distribution of in-ties for all the actors in the organization. Now the focus is on establishing a defensible threshold for identifying the most influential individuals in an organization. Visual inspection of the scree plot can make identifying influentials an onerous task. As an alternative, four reproducible methods are investigated for categorizing influential individuals in an organization. A detailed explanation of these methods follows. 

{\em Method 1 - Absolute Cut Score}

The simplest and most intuitive method for determining a cut score is to set a predetermined absolute value above which individuals are deemed influential and below which they are not. Graphically, this can be accomplished by super imposing a horizontal line over the in-degree scree plot. Those individuals whose influence scores are above the horizontal line are then categorized as influential. However, since this method is based entirely on a single point and is determined independent of variation in the distribution of in-ties, it can result in the situation where every individual (or no individual) in a network can potentially be deemed influential since the criterion is absolute, not relative.

{\em Method 2 - Fixed Percentage of Population}

An alternative method of identifying influentials is to select a fixed percentage of the population as influential. If the top 20\% of individuals in an organization are to be categorized as influentials, this is equivalent to selecting the left-most 20\% of the individuals in the graph. Those individuals to the left of a vertical line superimposed over the scree plot are categorised as influential. As with the Absolute Cut Score, this method identifies individuals as influential independent of the variation of in-ties. It ensures that a given percentage of individuals in the organization are identified as influential and their identification is based upon their performance relative to the performance of other individuals in the organization.

{\em Method 3 - Standard Deviation}

Unlike the first two approaches, the Standard Deviation method focuses on the variation in the distribution of ties. This procedure requires calculation of the mean and standard deviation of the number of in-ties. Then we create a horizontal line two standard deviations above the mean, which can be superimposed over the scree plot. Even though this horizontal line approach is similar to the Absolute Cut Score (Method 1), it however,  does not choose a cut score a priori, instead it utilizes the observed data in determining where to set the cut point. Under this method, those individuals whose in-degree scores are above this line are marked ”influential.”

{\em Method 4 - Random Permutation}

Through the use of random permutations, Method 4 produces results which identify those individuals who received significantly more in-ties than would have occurred by chance alone. This method capitalizes on the creation of a sampling distribution of potential networks that could have occurred, conditional on the fixed row marginals or (out-tie distribution). In order to obtain a sampling distribution of influence for the network, the graph (nodes and edges) is modelled as an exponential random graph. Then the edges are randomly reassigned to individuals in the network keeping the out-degree distribution fixed. By performing one thousand such random permutations the sampling distribution of influence (that is, in-degree distribution) is derived under conditional independence. The ties are not completely independent, as we restrict their new random locations to only emanate from their original sources in the actual data (i.e. the row marginals are fixed). However, in forcing this restriction, we are able to create a sampling distribution of influence that is comparable to our actual data. The result is the distribution that would arise by random chance, given the set of survey responses, and therefore can be used to identify those individuals whose influence is statistically greater than random chance. Once this is completed, individual influence scores are recalculated according to the in-degree measure described earlier. If an individuals actual influence score is higher than his/her ranked counterpart for 95\% of the random iterations, then the individual is labelled a significant influential at the $p > .05$ level.

\subsection{Time Series Analysis}

Time series analysis is an approach where data or datasets are analysed over discrete intervals of time such that processed data for a period of time say t0 serves as an input to time slot t1. The efforts here are to use novel methods so as to analyse the network, establish relations among nodes, predict and forecast the behaviour of social networks over a given period of time. With the help of temporal analysis methods and the underlying algorithms supporting them temporal distances and metrics are determined. 

Time series analysis consists of various steps namely estimation, prediction, query processing, result analysis and stimulation in order to get precise and aesthetically better results. It is used in engineering, business activities and sees application in various fields. Here, the attempt is to try and explore how a given social network reacts over time and how it behaves with the addition of new users, or which users tend to interact among each other, estimation of likelihood that a person X may collaborate with another person Y in future.

%%% ----------------------------------------------------------------------


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "../thesis"
%%% End: 
